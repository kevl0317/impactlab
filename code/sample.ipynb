{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.shared_net = NeuralNet2(input_size, output_size)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        return self.shared_net(x)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_2596\\1202294810.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  input1 = torch.tensor([pair[0] for pair in pairs], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "def generate_pairs(data, labels, num_pairs):\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "    num_samples = len(data)\n",
    "\n",
    "    for _ in range(num_pairs):\n",
    "        # Generate similar pair\n",
    "        idx1, idx2 = np.random.choice(num_samples, 2, replace=False)\n",
    "        if np.array_equal(labels[idx1], labels[idx2]):\n",
    "            pairs.append((data[idx1], data[idx2]))\n",
    "            pair_labels.append(1)\n",
    "        else:\n",
    "            pairs.append((data[idx1], data[idx2]))\n",
    "            pair_labels.append(0)\n",
    "\n",
    "    return pairs, pair_labels\n",
    "\n",
    "# Example dataset\n",
    "num_samples = 100\n",
    "input_size = 3000\n",
    "output_size = 7\n",
    "\n",
    "data = np.random.rand(num_samples, input_size)  # 100 samples of 3000-dim features\n",
    "labels = np.random.randint(0, 2, (num_samples, output_size))  # 100 labels of 7-dim arrays\n",
    "\n",
    "num_pairs = 200\n",
    "pairs, pair_labels = generate_pairs(data, labels, num_pairs)\n",
    "\n",
    "input1 = torch.tensor([pair[0] for pair in pairs], dtype=torch.float32)\n",
    "input2 = torch.tensor([pair[1] for pair in pairs], dtype=torch.float32)\n",
    "pair_labels = torch.tensor(pair_labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.02594587951898575\n",
      "Epoch 2/10, Loss: 0.029370969161391258\n",
      "Epoch 3/10, Loss: 0.01835859939455986\n",
      "Epoch 4/10, Loss: 0.013922043144702911\n",
      "Epoch 5/10, Loss: 0.012045676819980145\n",
      "Epoch 6/10, Loss: 0.011446717195212841\n",
      "Epoch 7/10, Loss: 0.011026685126125813\n",
      "Epoch 8/10, Loss: 0.010243542492389679\n",
      "Epoch 9/10, Loss: 0.009952994994819164\n",
      "Epoch 10/10, Loss: 0.009806645102798939\n"
     ]
    }
   ],
   "source": [
    "siamese_net = SiameseNetwork(input_size, output_size)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(siamese_net.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    output1, output2 = siamese_net(input1, input2)\n",
    "    loss = criterion(output1, output2, pair_labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0150\n",
      "Precision: 0.0102\n",
      "Recall: 0.5000\n",
      "F1-Score: 0.0199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Forward pass for evaluation\n",
    "output1, output2 = siamese_net(input1, input2)\n",
    "\n",
    "# Calculate Euclidean distances\n",
    "distances = F.pairwise_distance(output1, output2)\n",
    "\n",
    "# Determine an optimal threshold (for simplicity, let's use 0.5 here)\n",
    "threshold = 0.5\n",
    "\n",
    "# Predict labels based on the threshold\n",
    "predicted_labels = (distances < threshold).float()\n",
    "\n",
    "# Convert tensors to numpy arrays for metric calculation\n",
    "pair_labels_np = pair_labels.cpu().numpy()\n",
    "predicted_labels_np = predicted_labels.cpu().numpy()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(pair_labels_np, predicted_labels_np)\n",
    "precision = precision_score(pair_labels_np, predicted_labels_np)\n",
    "recall = recall_score(pair_labels_np, predicted_labels_np)\n",
    "f1 = f1_score(pair_labels_np, predicted_labels_np)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "impactlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
